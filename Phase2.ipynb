{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Phase2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsMjeRyfmkhf"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "class residual_block(nn.Module):\n",
        "\n",
        "    def __init__(self,channel_in,channel_out,ksize,ssize):\n",
        "        super(residual_block,self).__init__()\n",
        "        self.upper = nn.Conv2d(channel_in, channel_out, kernel_size=ksize,stride=ssize,padding=1)\n",
        "        self.lower = nn.Conv2d(channel_in, channel_out, kernel_size=ksize,stride=ssize,padding=1)\n",
        "        self.batch_norm0 = nn.BatchNorm2d(channel_out)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(channel_out)\n",
        "    def forward(self,x):\n",
        "        upper = self.batch_norm0(self.upper(x))\n",
        "        lower = self.batch_norm1(self.lower(x))\n",
        "        return torch.add(upper,lower)\n",
        "\n",
        "class Generator_zero(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Generator_zero, self).__init__()\n",
        "        self.conv0 = nn.Conv2d(3, 16, kernel_size=7, stride=1)\n",
        "        self.conv1 = nn.Conv2d(16, 64, kernel_size=7, stride=2)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=7, stride=2)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=7, stride=2)\n",
        "        self.conv4 = nn.Conv2d(256, 256, kernel_size=7, stride=2)\n",
        "        self.convT0 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2)\n",
        "        self.convT1 = nn.ConvTranspose2d(128, 128, kernel_size=3, stride=2)\n",
        "        self.convT2 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2)\n",
        "        self.convT3 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2)\n",
        "        self.convT4 = nn.Conv2d(32, 3, kernel_size=7, stride=1)\n",
        "        self.batch_norm0 = nn.BatchNorm2d(64)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(128)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(256)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(256)\n",
        "        self.batch_norm4 = nn.BatchNorm2d(128)\n",
        "        self.batch_norm5 = nn.BatchNorm2d(128)\n",
        "        self.batch_norm6 = nn.BatchNorm2d(64)\n",
        "        self.batch_norm7 = nn.BatchNorm2d(32)\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(10):\n",
        "            self.layers.append(residual_block(256,256,3,1))\n",
        "    \n",
        "    def forward(self, x,):\n",
        "        x = self.conv0(x)\n",
        "        x = F.relu(self.batch_norm0(self.conv1(x)))\n",
        "        x = F.relu(self.batch_norm1(self.conv2(x)))\n",
        "        x = F.relu(self.batch_norm2(self.conv3(x)))\n",
        "        x = F.relu(self.batch_norm3(self.conv4(x)))\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = layer(x)\n",
        "        residual = x\n",
        "        x = F.relu(self.batch_norm4(self.convT0(x)))\n",
        "        x = F.relu(self.batch_norm5(self.convT1(x)))\n",
        "        x = F.relu(self.batch_norm6(self.convT2(x)))\n",
        "        x = F.relu(self.batch_norm7(self.convT3(x)))\n",
        "        x = F.tanh(self.convT4(x))\n",
        "        return x,residual\n",
        "\n",
        "class Generator_one(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Generator_one, self).__init__()\n",
        "        self.conv0 = nn.Conv2d(3, 64, kernel_size=10, stride=10,padding=1)\n",
        "        self.conv1 = nn.Conv2d(64, 256, kernel_size=8, stride=8)\n",
        "        self.convT0 = nn.ConvTranspose2d(256, 32, kernel_size=3, stride=3)\n",
        "        self.convT1 = nn.Conv2d(32, 3, kernel_size=7, stride=1)\n",
        "        self.batch_norm0 = nn.BatchNorm2d(256)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(7):\n",
        "            self.layers.append(residual_block(256,256,3,1))\n",
        "    \n",
        "    def forward(self, x,low_res):\n",
        "        x = self.conv0(x)\n",
        "        x = F.relu(self.batch_norm0(self.conv1(x)))\n",
        "        print(x.shape,\"x\",low_res.shape)\n",
        "        x = torch.add(x,low_res)\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = layer(x)\n",
        "        residual = x.clone().detach()\n",
        "        x = F.relu(self.batch_norm1(self.convT0(x)))\n",
        "        x = F.tanh(self.convT1(x))\n",
        "        return x,residual\n",
        "\n",
        "class Generator_two(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Generator_two, self).__init__()\n",
        "        self.conv0 = nn.Conv2d(3, 64, kernel_size=3, stride=1)\n",
        "        self.convT0 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2)\n",
        "        self.convT1 = nn.Conv2d(32, 3, kernel_size=7, stride=1)\n",
        "        self.batch_norm0 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(4):\n",
        "            self.layers.append(residual_block(64,64,3,1))\n",
        "    \n",
        "    def forward(self, x,mid_res):\n",
        "        x = self.conv0(x)\n",
        "        torch.add(x,mid_res)\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = layer(x)\n",
        "        residual = x.clone().detach()\n",
        "        x = F.relu(self.batch_norm0(self.convT0(x)))\n",
        "        x = F.tanh(self.convT1(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator_zero(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Discriminator_zero, self).__init__()\n",
        "        self.conv0 = nn.Conv2d(3, 64, kernel_size=3, stride=1)\n",
        "        self.conv1 = nn.Conv2d(64, 128, kernel_size=3, stride=2)\n",
        "        self.conv2 = nn.Conv2d(128, 256, kernel_size=3, stride=2)\n",
        "        self.conv3 = nn.Conv2d(256, 512, kernel_size=3, stride=2)\n",
        "        self.conv4 = nn.Conv2d(512, 1, kernel_size=3, stride=2)\n",
        "        self.batch_norm0 = nn.BatchNorm2d(128)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(256)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(512)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(1)\n",
        "    \n",
        "    def forward(self, x,matching=False):\n",
        "        x = self.conv0(x)\n",
        "        x = F.relu(self.batch_norm0(self.conv1(x)))\n",
        "        x = F.relu(self.batch_norm1(self.conv2(x)))\n",
        "        x = F.relu(self.batch_norm2(self.conv3(x)))\n",
        "        x = F.relu(self.batch_norm3(self.conv4(x)))\n",
        "\n",
        "        return x\n",
        "\n",
        "class Discriminator_one(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Discriminator_one, self).__init__()\n",
        "        self.conv0 = nn.Conv2d(3, 64, kernel_size=3, stride=1)\n",
        "        self.conv1 = nn.Conv2d(64, 128, kernel_size=3, stride=2)\n",
        "        self.conv2 = nn.Conv2d(128, 256, kernel_size=3, stride=2)\n",
        "        self.conv3 = nn.Conv2d(256, 512, kernel_size=3, stride=2)\n",
        "        self.conv4 = nn.Conv2d(512, 1, kernel_size=3, stride=2,padding=1)\n",
        "        self.batch_norm0 = nn.BatchNorm2d(128)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(256)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(512)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(1)\n",
        "    \n",
        "    def forward(self, x,matching=False):\n",
        "        x = self.conv0(x)\n",
        "        x = F.relu(self.batch_norm0(self.conv1(x)))\n",
        "        x = F.relu(self.batch_norm1(self.conv2(x)))\n",
        "        x = F.relu(self.batch_norm2(self.conv3(x)))\n",
        "        x = F.relu(self.batch_norm3(self.conv4(x)))\n",
        "        \n",
        "        return x\n",
        "class Discriminator_two(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Discriminator_two, self).__init__()\n",
        "        self.conv0 = nn.Conv2d(3, 64, kernel_size=3, stride=1)\n",
        "        self.conv1 = nn.Conv2d(64, 128, kernel_size=3, stride=2)\n",
        "        self.conv2 = nn.Conv2d(128, 256, kernel_size=3, stride=2)\n",
        "        self.conv3 = nn.Conv2d(256, 512, kernel_size=3, stride=2)\n",
        "        self.conv4 = nn.Conv2d(512, 1, kernel_size=3, stride=2)\n",
        "        self.batch_norm0 = nn.BatchNorm2d(128)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(256)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(512)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(1)\n",
        "    \n",
        "    def forward(self, x,matching=False):\n",
        "        x = self.conv0(x)\n",
        "        x = F.relu(self.batch_norm0(self.conv1(x)))\n",
        "        x = F.relu(self.batch_norm1(self.conv2(x)))\n",
        "        x = F.relu(self.batch_norm2(self.conv3(x)))\n",
        "        x = F.relu(self.batch_norm3(self.conv4(x)))\n",
        "        \n",
        "        return x\n"
      ],
      "metadata": {
        "id": "kzb-ZHz3mtob"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}